{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYMptiYgrcp6fAbhu3/1h2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ridazaneb/IndoFashionCLIP/blob/main/IndoFashionCLIP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AnC6kPHg8De5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq452tiQkU0n",
        "outputId": "a099f609-aeac-4fef-ac41-926e9e94faa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (6.3.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.44.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy) (0.2.13)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.35.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n"
          ]
        }
      ],
      "source": [
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "\n",
        "# Base path to your Indofashion folder\n",
        "BASE = '/content/drive/MyDrive/IndoFashion'\n",
        "\n",
        "# Install deps (if not already)\n",
        "!pip install torch torchvision transformers ftfy regex tqdm pandas scikit-learn streamlit Pillow opencv-python\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, os, shutil\n",
        "\n",
        "# Paths\n",
        "BASE_DRIVE = \"/content/drive/MyDrive/IndoFashion\"\n",
        "FULL_CSV   = os.path.join(BASE_DRIVE, \"data/train.csv\")\n",
        "SUB_CSV    = os.path.join(BASE_DRIVE, \"data/train_sub.csv\")\n",
        "IMG_SRC    = BASE_DRIVE      # used for copying\n",
        "IMG_DST    = \"/content/images_sub\"\n",
        "\n",
        "# 1) Sample 10 000 rows from train.csv\n",
        "df = pd.read_csv(FULL_CSV)\n",
        "sub = df.sample(n=500, random_state=42).reset_index(drop=True)\n",
        "sub.to_csv(SUB_CSV, index=False)\n",
        "print(f\"Created subset CSV → {SUB_CSV} ({len(sub)} rows)\")\n",
        "\n",
        "# 2) Copy only those image files locally\n",
        "os.makedirs(IMG_DST, exist_ok=True)\n",
        "for img_path in sub[\"image_path\"]:\n",
        "    src = os.path.join(BASE_DRIVE, img_path)         # e.g. …/images/train/123.jpeg\n",
        "    dst = os.path.join(IMG_DST, img_path)            # e.g. /content/images_sub/images/train/123.jpeg\n",
        "    os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
        "    shutil.copy2(src, dst)\n",
        "print(f\"Copied {len(sub)} images → {IMG_DST}\")\n"
      ],
      "metadata": {
        "id": "hmgN2mWwABZK",
        "outputId": "4aca21dc-1230-4a8e-b586-9a1fbc261a61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created subset CSV → /content/drive/MyDrive/IndoFashion/data/train_sub.csv (500 rows)\n",
            "Copied 500 images → /content/images_sub\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, os\n",
        "\n",
        "BASE_DRIVE = \"/content/drive/MyDrive/IndoFashion\"\n",
        "VAL_CSV    = os.path.join(BASE_DRIVE, \"data/val.csv\")\n",
        "VAL_SUB    = os.path.join(BASE_DRIVE, \"data/val_sub.csv\")\n",
        "\n",
        "# Load full validation\n",
        "df_val = pd.read_csv(VAL_CSV)\n",
        "\n",
        "# Sample 500 (or whatever you like)\n",
        "df_val_sub = df_val.sample(n=500, random_state=42)\n",
        "df_val_sub.to_csv(VAL_SUB, index=False)\n",
        "print(f\"[✓] Created {VAL_SUB} ({len(df_val_sub)} rows)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tb0CQ7DJTwDy",
        "outputId": "2dbdeda5-4f12-4274-8d1b-d6df7d4c4b4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[✓] Created /content/drive/MyDrive/IndoFashion/data/val_sub.csv (500 rows)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# adjust paths to match your Drive layout\n",
        "SOURCE=\"/content/drive/MyDrive/IndoFashion/images/\"\n",
        "DEST=\"/content/images/\"\n",
        "rsync -av --info=progress2 \"$SOURCE\" \"$DEST\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnJku6TZ8Q2Z",
        "outputId": "682ead67-13be-4d9d-b1a9-1ffe82cdd9cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process is terminated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scripts/prepare_splits.py\n",
        "import json, os, pandas as pd\n",
        "\n",
        "BASE = '/content/drive/MyDrive/IndoFashion'\n",
        "OUT = os.path.join(BASE, 'data')\n",
        "os.makedirs(OUT, exist_ok=True)\n",
        "\n",
        "def make_caption(rec):\n",
        "    cls = rec.get('class_label','').lower()\n",
        "    color = rec.get('color') or ''\n",
        "    if not color:\n",
        "        # try to pull a color from the title\n",
        "        for c in ['red','green','blue','yellow','pink','black','white',\n",
        "                  'beige','brown','orange','multicolor']:\n",
        "            if c in rec.get('product_title','').lower():\n",
        "                color=c; break\n",
        "    person = 'woman' if cls in ['saree','lehenga','kurta',\n",
        "                                'dupatta','gown','petticoats'] else 'man'\n",
        "    return f\"a {person} wearing a {color} {cls}\".strip()\n",
        "\n",
        "for split in ['train','val','test']:\n",
        "    js_file = os.path.join(BASE, f'{split}_data.json')\n",
        "    with open(js_file) as f:\n",
        "        # JSON-lines or array? adjust accordingly\n",
        "        try:\n",
        "            records = [json.loads(line) for line in f]\n",
        "        except:\n",
        "            records = json.load(f)\n",
        "    for r in records:\n",
        "        r['caption'] = make_caption(r)\n",
        "    df = pd.DataFrame(records)\n",
        "    csv_path = os.path.join(OUT, f'{split}.csv')\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(f\"[✓] {split}.csv ← {len(df)} rows\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3kjjG3hkmLJ",
        "outputId": "653c86fc-8817-441c-b483-d8ee2276accc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[✓] train.csv ← 91166 rows\n",
            "[✓] val.csv ← 7500 rows\n",
            "[✓] test.csv ← 7500 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# adjust paths to match your Drive layout\n",
        "SOURCE=\"/content/drive/MyDrive/Indofashion/images/\"\n",
        "DEST=\"/content/images/\"\n",
        "rsync -av --info=progress2 \"$SOURCE\" \"$DEST\"\n"
      ],
      "metadata": {
        "id": "dfUfyx867nQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Mount & install (if you haven’t already)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "!pip install torch torchvision transformers ftfy regex tqdm pandas scikit-learn Pillow\n",
        "\n",
        "# 2) Set paths\n",
        "import os\n",
        "BASE      = '/content/drive/MyDrive/IndoFashion'\n",
        "TRAIN_CSV = os.path.join(BASE, 'data/train_sub.csv')\n",
        "IMG_ROOT   = '/content/images_sub'     # local copy of just the subset\n",
        "VAL_CSV   = os.path.join(BASE, 'data/val_sub.csv')     # now also 500‐row val\n",
        "MODEL_DIR = os.path.join(BASE, 'models/clip_south_asia')\n",
        "\n",
        "# 3) Build dataset & loader\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "class FashionDataset(Dataset):\n",
        "    def __init__(self, csv_path, processor):\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        self.proc = processor\n",
        "        self.tf = transforms.Compose([\n",
        "            transforms.Resize((128,256)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.ColorJitter(),\n",
        "        ])\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        # row['image_path'] is e.g. \"images/test/0.jpeg\"\n",
        "        img_path = os.path.join(BASE, row['image_path'])\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img = self.tf(img)\n",
        "        enc = self.proc(text=row['caption'],\n",
        "                        images=img,\n",
        "                        return_tensors='pt',\n",
        "                        padding=True)\n",
        "        # squeeze batch dim\n",
        "        return {k: v.squeeze(0) for k,v in enc.items()}\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # Pad the 'input_ids' and 'attention_mask' tensors to the maximum length in the batch\n",
        "    max_len = max([d['input_ids'].shape[0] for d in batch])\n",
        "    padded_input_ids = [torch.cat((d['input_ids'], torch.zeros(max_len - d['input_ids'].shape[0], dtype=d['input_ids'].dtype)), dim=0) for d in batch]\n",
        "    padded_attention_mask = [torch.cat((d['attention_mask'], torch.zeros(max_len - d['attention_mask'].shape[0], dtype=d['attention_mask'].dtype)), dim=0) for d in batch]\n",
        "\n",
        "    # Stack the padded tensors and other tensors\n",
        "    return {\n",
        "        'input_ids': torch.stack(padded_input_ids),\n",
        "        'attention_mask': torch.stack(padded_attention_mask),\n",
        "        'pixel_values': torch.stack([d['pixel_values'] for d in batch])\n",
        "    }\n",
        "\n",
        "# 4) Initialize model, processor, loaders\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model  = CLIPModel.from_pretrained('openai/clip-vit-base-patch32').to(device)\n",
        "proc   = CLIPProcessor.from_pretrained('openai/clip-vit-base-patch32')\n",
        "\n",
        "train_ds = FashionDataset(TRAIN_CSV, proc)\n",
        "val_ds   = FashionDataset(VAL_CSV,   proc)\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True,\n",
        "                          num_workers=0, pin_memory=True,\n",
        "                          collate_fn=collate_fn)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=64, shuffle=False,\n",
        "                          num_workers=0, pin_memory=True,\n",
        "                          collate_fn=collate_fn)\n",
        "\n",
        "# 5) Training loop\n",
        "from torch import optim\n",
        "opt = optim.AdamW(model.parameters(), lr=5e-6, weight_decay=1e-2)\n",
        "for epoch in range(4):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch} train\"):\n",
        "        opt.zero_grad()\n",
        "        # Add return_loss=True to get the loss value\n",
        "        out = model(**{k:v.to(device) for k,v in batch.items()}, return_loss=True)\n",
        "        out.loss.backward()\n",
        "        opt.step()\n",
        "        total_loss += out.loss.item()\n",
        "    print(f\"→ Train Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc=\"Epoch valid\"):\n",
        "            # Add return_loss=True to get the loss value\n",
        "            val_loss += model(**{k:v.to(device) for k,v in batch.items()}, return_loss=True).loss.item()\n",
        "    print(f\"→ Val   Loss: {val_loss/len(val_loader):.4f}\")\n",
        "\n",
        "# 6) Save your fine-tuned model\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "model.save_pretrained(MODEL_DIR)\n",
        "proc.save_pretrained(MODEL_DIR)\n",
        "print(\"Saved fine-tuned CLIP to\", MODEL_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdflhBkEsD4j",
        "outputId": "b8df06da-a11a-48d9-ed18-7e1e1014a5f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (6.3.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy) (0.2.13)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 0 train: 100%|██████████| 8/8 [04:47<00:00, 35.97s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "→ Train Loss: 3.3512\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch valid: 100%|██████████| 8/8 [03:57<00:00, 29.67s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "→ Val   Loss: 2.6425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 train: 100%|██████████| 8/8 [04:43<00:00, 35.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ Train Loss: 2.3456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch valid: 100%|██████████| 8/8 [01:32<00:00, 11.53s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ Val   Loss: 2.3590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 train: 100%|██████████| 8/8 [04:33<00:00, 34.14s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ Train Loss: 1.9735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch valid: 100%|██████████| 8/8 [01:37<00:00, 12.22s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ Val   Loss: 2.2485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 train: 100%|██████████| 8/8 [04:38<00:00, 34.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ Train Loss: 1.6635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch valid: 100%|██████████| 8/8 [01:35<00:00, 11.97s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ Val   Loss: 2.2384\n",
            "Saved fine-tuned CLIP to /content/drive/MyDrive/IndoFashion/models/clip_south_asia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scripts/trend_cluster.py\n",
        "\n",
        "import torch, pickle, os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "BASE      = '/content/drive/MyDrive/IndoFashion'\n",
        "MODEL_DIR = os.path.join(BASE,'models/clip_south_asia')\n",
        "TRAIN_CSV = os.path.join(BASE, 'data/train_sub.csv')\n",
        "IMG_ROOT   = '/content/images_sub'\n",
        "\n",
        "def extract_embeddings(model, proc, df):\n",
        "    embs=[]\n",
        "    for _,r in tqdm(df.iterrows(), total=len(df)):\n",
        "        img = Image.open(os.path.join(IMG_ROOT, r['image_path'])).convert('RGB')\n",
        "        inp = proc(images=img, return_tensors='pt').to(model.device)\n",
        "        with torch.no_grad():\n",
        "            emb = model.get_image_features(**inp)\n",
        "        embs.append(emb.cpu().numpy().squeeze())\n",
        "    return np.vstack(embs)\n",
        "\n",
        "def main():\n",
        "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model = CLIPModel.from_pretrained(MODEL_DIR).to(device).eval()\n",
        "    proc  = CLIPProcessor.from_pretrained(MODEL_DIR)\n",
        "    df = pd.read_csv(TRAIN_CSV)\n",
        "\n",
        "    embs = extract_embeddings(model, proc, df)\n",
        "    pca  = PCA(n_components=50).fit(embs)\n",
        "    lowd = pca.transform(embs)\n",
        "    km   = KMeans(n_clusters=20, random_state=42).fit(lowd)\n",
        "\n",
        "    df['cluster'] = km.labels_\n",
        "    df.to_csv(os.path.join(BASE,'outputs/train_with_clusters.csv'), index=False)\n",
        "    pickle.dump((pca,km), open(os.path.join(BASE,'models/pca_km.pkl'),'wb'))\n",
        "    print(\"[✓] Clustering done → outputs/train_with_clusters.csv\")\n",
        "\n",
        "if __name__=='__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yzsoR7dO_m2",
        "outputId": "da7a8723-fc48-41f7-a297-a4b701c9130a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [02:06<00:00,  3.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[✓] Clustering done → outputs/train_with_clusters.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scripts/app_dashboard.py\n",
        "\n",
        "import streamlit as st, os, pickle, torch\n",
        "import pandas as pd, numpy as np\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "\n",
        "BASE       = '/content/drive/MyDrive/IndoFashion'\n",
        "MODEL_DIR  = os.path.join(BASE,'models/clip_south_asia')\n",
        "PKL_FILE   = os.path.join(BASE,'models/pca_km.pkl')\n",
        "CLUSTER_CSV= os.path.join(BASE,'outputs/train_with_clusters.csv')\n",
        "IMG_ROOT   = '/content/images_sub'\n",
        "\n",
        "@st.cache_resource\n",
        "def load_all():\n",
        "    model = CLIPModel.from_pretrained(MODEL_DIR).to('cpu').eval()\n",
        "    proc  = CLIPProcessor.from_pretrained(MODEL_DIR)\n",
        "    pca, km = pickle.load(open(PKL_FILE,'rb'))\n",
        "    df = pd.read_csv(CLUSTER_CSV)\n",
        "    return model, proc, pca, km, df\n",
        "\n",
        "model, proc, pca, km, df = load_all()\n",
        "\n",
        "st.title(\"South Asian Fashion Trend Predictor\")\n",
        "uploaded = st.file_uploader(\"Upload an image\", type=[\"jpg\",\"png\"])\n",
        "if uploaded:\n",
        "    img = Image.open(uploaded).convert(\"RGB\")\n",
        "    st.image(img, use_column_width=True)\n",
        "\n",
        "    # predict class\n",
        "    enc = proc(images=img, return_tensors=\"pt\", padding=True)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**enc).logits_per_image\n",
        "    probs = logits.softmax(dim=1).cpu().numpy().squeeze()\n",
        "    topk = np.argsort(-probs)[:5]\n",
        "    st.subheader(\"Top Predictions\")\n",
        "    for idx in topk:\n",
        "        st.write(f\"{model.config.id2label[idx]}: {probs[idx]*100:.1f}%\")\n",
        "\n",
        "    # cluster\n",
        "    emb = model.get_image_features(**enc)\n",
        "    low = pca.transform(emb.cpu().numpy())\n",
        "    cl  = km.predict(low)[0]\n",
        "    st.write(f\"Style Cluster: {cl}\")\n",
        "\n",
        "    st.subheader(\"Similar Styles\")\n",
        "    samples = df[df.cluster==cl].sample(8)\n",
        "    cols = st.columns(4)\n",
        "    for i,(_,r) in enumerate(samples.iterrows()):\n",
        "        with cols[i%4]:\n",
        "            im = Image.open(os.path.join(IMG_ROOT, r.image_path))\n",
        "            st.image(im, use_column_width=True)\n",
        "            st.caption(r.class_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1LFiRLDcoRa",
        "outputId": "c2e0cb77-b557-42c9-ab61-1ae2d0e503eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-28 12:50:36.297 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-28 12:50:36.535 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-04-28 12:50:36.536 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-28 12:50:36.538 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-28 12:50:37.041 Thread 'Thread-20': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-28 12:50:37.043 Thread 'Thread-20': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-28 12:50:37.627 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-28 12:50:37.628 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-28 12:50:37.629 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-28 12:50:37.630 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-28 12:50:37.631 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-28 12:50:37.632 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-28 12:50:37.633 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-28 12:50:37.634 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-28 12:50:37.635 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "mkdir -p /content/drive/MyDrive/Indofashion/scripts\n"
      ],
      "metadata": {
        "id": "pXNeOglRdajZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat << 'EOF' > /content/drive/MyDrive/IndoFashion/scripts/app_dashboard.py\n",
        "# scripts/app_dashboard.py\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import streamlit as st\n",
        "import torch\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "\n",
        "# ───────────────────────────────────────────────────────────\n",
        "# CONFIG\n",
        "# ───────────────────────────────────────────────────────────\n",
        "BASE_DIR   = '/content/drive/MyDrive/IndoFashion'\n",
        "MODEL_DIR  = os.path.join(BASE_DIR, 'models/clip_south_asia')\n",
        "TEST_CSV   = os.path.join(BASE_DIR, 'data/test.csv')\n",
        "CLUSTER_CSV= os.path.join(BASE_DIR, 'data/train_with_clusters.csv')\n",
        "CLUSTER_PKL= os.path.join(BASE_DIR, 'models/pca_km.pkl')\n",
        "\n",
        "# Try local SSD first, else fall back to Drive\n",
        "IMG_ROOT = '/content/images'\n",
        "if not os.path.isdir(IMG_ROOT):\n",
        "    IMG_ROOT = os.path.join(BASE_DIR, 'images')\n",
        "\n",
        "# ───────────────────────────────────────────────────────────\n",
        "# RESOURCE LOADING\n",
        "# ───────────────────────────────────────────────────────────\n",
        "@st.cache_resource(show_spinner=False)\n",
        "def load_model_and_classes():\n",
        "    device    = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model     = CLIPModel.from_pretrained(MODEL_DIR).to(device)\n",
        "    processor = CLIPProcessor.from_pretrained(MODEL_DIR)\n",
        "    classes   = pd.read_csv(TEST_CSV)['class_label'].unique().tolist()\n",
        "    return model, processor, device, classes\n",
        "\n",
        "@st.cache_resource(show_spinner=False)\n",
        "def load_cluster_data():\n",
        "    df      = pd.read_csv(CLUSTER_CSV)\n",
        "    with open(CLUSTER_PKL, 'rb') as f:\n",
        "        pca_km = pickle.load(f)\n",
        "    return df, pca_km['pca'], pca_km['km']\n",
        "\n",
        "model, processor, device, class_list = load_model_and_classes()\n",
        "\n",
        "# Cluster artifacts may not exist yet\n",
        "try:\n",
        "    df_clusters, pca, km = load_cluster_data()\n",
        "    clustering_enabled = True\n",
        "except Exception:\n",
        "    clustering_enabled = False\n",
        "\n",
        "# ───────────────────────────────────────────────────────────\n",
        "# APP UI\n",
        "# ───────────────────────────────────────────────────────────\n",
        "st.set_page_config(page_title=\"South Asian Fashion Classifier\")\n",
        "st.title(\"🌺 South Asian Fashion Classifier\")\n",
        "\n",
        "uploaded = st.file_uploader(\"Upload an image of a garment\", type=['jpg','png','jpeg'])\n",
        "if uploaded:\n",
        "    # Display upload\n",
        "    img = Image.open(uploaded).convert('RGB')\n",
        "    st.image(img, caption=\"Your Upload\", use_container_width=True)\n",
        "\n",
        "    # Preprocess & forward pass\n",
        "    inputs = processor(images=img, return_tensors=\"pt\", padding=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        img_feats = model.get_image_features(**inputs)\n",
        "        img_feats = img_feats / img_feats.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        text_inputs = processor(\n",
        "            text=[f\"a {c}\" for c in class_list],\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True\n",
        "        ).to(device)\n",
        "\n",
        "        txt_feats = model.get_text_features(**text_inputs)\n",
        "        txt_feats = txt_feats / txt_feats.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        sims  = (img_feats @ txt_feats.T)[0]\n",
        "        probs = sims.softmax(dim=0)\n",
        "        top3  = torch.topk(probs, k=3)\n",
        "\n",
        "    # Show Top-3 predictions\n",
        "    st.subheader(\"Top 3 Predictions\")\n",
        "    for score, idx in zip(top3.values, top3.indices):\n",
        "        cls = class_list[idx]\n",
        "        st.write(f\"• **{cls.upper()}** — {float(score):.2%}\")\n",
        "\n",
        "    # Optional: Similar styles gallery via clustering\n",
        "    if clustering_enabled:\n",
        "        emb   = img_feats.cpu().numpy()\n",
        "        emb_p = pca.transform(emb)\n",
        "        cid   = int(km.predict(emb_p)[0])\n",
        "\n",
        "        st.markdown(f\"### Similar styles (cluster {cid})\")\n",
        "        cols = st.columns(4)\n",
        "        samples = df_clusters[df_clusters.cluster == cid] \\\n",
        "                      .sample(4, random_state=42)['image_path'].tolist()\n",
        "\n",
        "        for col, img_path in zip(cols, samples):\n",
        "            full_path = os.path.join(IMG_ROOT, img_path)\n",
        "            try:\n",
        "                thumb = Image.open(full_path).convert('RGB')\n",
        "                col.image(thumb, use_container_width=True, caption=os.path.basename(img_path))\n",
        "            except Exception:\n",
        "                col.write(\"❓ missing image\")\n",
        "\n",
        "else:\n",
        "    st.info(\"Please upload a JPG/PNG image of a South Asian garment to get started.\")\n",
        "\n",
        "EOF\n"
      ],
      "metadata": {
        "id": "K91OvpO9d3cI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Install streamlit if you haven’t already\n",
        "!pip install streamlit\n",
        "\n",
        "# 2) Start Streamlit in the background on port 8501\n",
        "get_ipython().system_raw(\n",
        "    'streamlit run /content/drive/MyDrive/IndoFashion/scripts/app_dashboard.py '\n",
        "    '--server.port 8501 --server.address 0.0.0.0 &'\n",
        ")\n",
        "\n",
        "# 3) Embed the app directly in your notebook\n",
        "from google.colab import output\n",
        "output.serve_kernel_port_as_iframe(8501)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "svrEirARd65A",
        "outputId": "a7135535-fd15-48a0-9f7b-4441432304e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.44.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.35.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(8501, \"/\", \"100%\", \"400\", false, window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install streamlit pyngrok -q\n",
        "\n",
        "# Launch Streamlit in the background\n",
        "import os, sys\n",
        "get_ipython().system_raw(\n",
        "  'streamlit run /content/drive/MyDrive/IndoFashion/scripts/app_dashboard.py '\n",
        "  '--server.port 8501 --server.address 0.0.0.0 &'\n",
        ")\n",
        "\n",
        "# Expose port 8501 via ngrok\n",
        "from pyngrok import ngrok, conf\n",
        "conf.get_default().region = \"us\"          # or your region\n",
        "!ngrok authtoken 2wMKDmHaYBa1GjhPzYFvqgYduZh_2sraK1GftHFV3cAKW5MRd  # Removed the colon and leading space\n",
        "public_url = ngrok.connect(8501, \"http\")\n",
        "print(\"🔗 Public URL:\", public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "Ak6XxA1rfnmZ",
        "outputId": "9976e0ba-65f9-4bc4-aa35-cc956221fcfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-04-28T13:22:03+0000 lvl=warn msg=\"failed to start tunnel\" pg=/api/tunnels id=9dad1ab5d0382de4 err=\"failed to start tunnel: Your account may not run more than 3 tunnels over a single ngrok agent session.\\nThe tunnels already running on this session are:\\ntn_2wMKHKDOzbYOc5GVoTuhpIWp1Ns, tn_2wMKbWWOKkKvMzucs1dxeWHPjJC, tn_2wMLKCEhL49UivnUodGropWKt4n\\n\\r\\n\\r\\nERR_NGROK_324\\r\\n\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PyngrokNgrokHTTPError",
          "evalue": "ngrok client exception, API returned 502: {\"error_code\":103,\"status_code\":502,\"msg\":\"failed to start tunnel\",\"details\":{\"err\":\"failed to start tunnel: Your account may not run more than 3 tunnels over a single ngrok agent session.\\nThe tunnels already running on this session are:\\ntn_2wMKHKDOzbYOc5GVoTuhpIWp1Ns, tn_2wMKbWWOKkKvMzucs1dxeWHPjJC, tn_2wMLKCEhL49UivnUodGropWKt4n\\n\\r\\n\\r\\nERR_NGROK_324\\r\\n\"}}\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(url, method, data, params, timeout, auth)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0mresponse_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    635\u001b[0m                 'http', request, response, code, msg, hdrs)\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 502: Bad Gateway",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mPyngrokNgrokHTTPError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-9a1446a3ea25>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"us\"\u001b[0m          \u001b[0;31m# or your region\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ngrok authtoken 2wMKDmHaYBa1GjhPzYFvqgYduZh_2sraK1GftHFV3cAKW5MRd  # Removed the colon and leading space'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mpublic_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8501\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"http\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🔗 Public URL:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublic_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Creating tunnel with options: {options}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     tunnel = NgrokTunnel(api_request(f\"{api_url}/api/tunnels\", method=\"POST\", data=options,\n\u001b[0m\u001b[1;32m    355\u001b[0m                                      timeout=pyngrok_config.request_timeout),\n\u001b[1;32m    356\u001b[0m                          pyngrok_config, api_url)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(url, method, data, params, timeout, auth)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Response {status_code}: {response_data.strip()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         raise PyngrokNgrokHTTPError(f\"ngrok client exception, API returned {status_code}: {response_data}\",\n\u001b[0m\u001b[1;32m    578\u001b[0m                                     \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m                                     status_code, e.reason, e.headers, response_data)\n",
            "\u001b[0;31mPyngrokNgrokHTTPError\u001b[0m: ngrok client exception, API returned 502: {\"error_code\":103,\"status_code\":502,\"msg\":\"failed to start tunnel\",\"details\":{\"err\":\"failed to start tunnel: Your account may not run more than 3 tunnels over a single ngrok agent session.\\nThe tunnels already running on this session are:\\ntn_2wMKHKDOzbYOc5GVoTuhpIWp1Ns, tn_2wMKbWWOKkKvMzucs1dxeWHPjJC, tn_2wMLKCEhL49UivnUodGropWKt4n\\n\\r\\n\\r\\nERR_NGROK_324\\r\\n\"}}\n"
          ]
        }
      ]
    }
  ]
}